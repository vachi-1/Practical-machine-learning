xt <- xn/sd(x)
xt
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
f <- lm(y~x)
summary(f)
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
mean(x)
library(swirl)
swirl()
swirl()
plot(child~parent, data=galton)
plot(jitter(child,4) ~parent, galton)
regrline <- im(child~parent, data=galton)
regrline <- lm(child~parent, data=galton)
abline(regrline, lwd=3, col = "red")
summary(regrline)
fit <- lm(child~parent, data = galton)
summary(fit)
mean(fit$residuals)
cov(fit$residuals, galton$parent)
ols.ic <- fit$cof [1]
ols.ic <- fit$coef[1]
ols.slope <- fit$coef[2]
rhs - lhs
lhs-rhs
all.equal(lhs, rhs)
varChild <- var(child)
varChild <- var(galton$child)
varRes <- var(fit$residuals)
varEst <- var(est(galton$child))
varEst <- var(est(ols.ic + ols.slope*galton$child))
varEst <- var(est(ols.slope, ols.ic))
all.equal(varChild, sum(varRes, varEst))
all.equal(varChild, varRes+varEst))
all.equal(varChild, varRes+varEst)
efit <- lm(accel~mag+dist, data = attenu)
mean(efit$residuals)
cov(efit$residuals, attenu$mag)
cov(efit$residuals, attenu$dist)
cor(gpa_nor, gch_nor)
l_nor <- lm(gch_nor~gpa_nor)
fit <- lm(child~parent, data = galton)
(sum(fit$residuals)/926)^2
(sum(fit$residuals)/926)^1/2
sqrt(sum(fit$residuals^2) / (n - 2))
summary(fit)$sigma
squrt(deviance(fit)/(n-2))
sqrt(deviance(fit)/(n-2))
mu <- mean(galton$child)
sTot <- sum((galton$child- mu)^2)
sRes <- deviance(fit)
sRes/sTot
1- sRes/sTot
summary(fit)$r.squared
sqrt(cor(galton$child, galton$parent)
)
cor(galton$child, galton$parent)^2
bye9)
bye())
bye()
exit()
library(UsingR)
data(galton)
data(father.son)
fit <- lm(sheight~fheight, data = father.son)
fit <- lm(sheight~fheight, data = father.son)
summary(fit)
summary(fit)$coef
fit2 <- lm(sheight~I(fheight - mean(fheight)), data = father.son)
summary(fit2)$coef
fit <- lm(sheight~fheight, data = father.son)
predict(fit, newdata = data.frame(fheight = 80))
data(mtcars)
str(mtcars)
fit3 <- lm(mpg~hp, data = mtcars)
summary(fit3$coef)
summary(fit3)$coef
fit4 <- lm(mpg~I(hp - mean(hp), data = mtcars
fit4 <- lm(mpg~I(hp - mean(hp), data = mtcars)
fit4 <- lm(mpg~I(hp - mean(hp), data = mtcars)
fit4 <- lm(mpg~I(hp - mean(hp)), data = mtcars)
fit4 <- lm(mpg~I(hp - mean(hp)), data = mtcars)
summary(fit4)$coef
summary(fit4)$coef
library(ggplot2)
g <- ggplot(mtcars, aes(x = hp, y = mpg))
g <- g + geom_point(cex = 5, alpha = .5)
g <- g + geom_smooth(method = lm, se = FALSE, lwd = 2)
g
summary(fit3)$coef
predict(fit3, newdata = data.frame(hp = 111))
library(UsingR)
data(father.son)
fit <- lm(sheight~fheight, data = father.son)
summary(fit)
summary(fit)$r.squared
data(mtcars)
fit2 <- lm(mpg~hp, data = mtcars)
temp <- mtcars; temp$resid <- resid(fit)
temp = mtcars; temp$resid = resid(fit)
temp = mtcars; temp$resid = resid(fit2)
library(ggplot2)
g <- ggplot(temp, aes(x = hp, y = resid))
g <- g + geom_hline(yintercept = 0, col = "red")
g <- g + geom_point(alpha = 0.5, cex = 5)
g
sum(resid(fit2)^2)/(nrow(mtcars) -2)
summary(fit)$sigma^2
summary(fit2)$sigma^2
summary(fit2)$r.squared
data(father.son)
fit <- lm(sheight~fheight, data = father.son)
summary(fit)
confint(fit)
fit <- lm(sheight~I(fheight - mean(feight)), data = father.son)
fit <- lm(sheight~I(fheight - mean(fheight)), data = father.son)
confint(fit)
m <- mean(father.son$fheight)
m
predict(fit, newdata = data.frame(fheight = m), interval = "confidence")
predict(fit, newdata = data.frame(fheight = m), interval = "prediction")
library(Datasets)
library(datasets)
data("Seatbelts")
seatbelts = as.data.frame(seatbelts)
seatbelts = as.data.frame(Seatbelts)
head(seatbelt)
head(seatbelts)
fit <- lm(Driverskilled~PetrolPrice + kms, data = seatbelts)
fit <- lm(DriversKilled~PetrolPrice + kms, data = seatbelts)
summary(fit)$coef
round(summary(fit)$coef, 4)
library(swirl)
swirl()
ones <- rep(1, nrow(galton))
lm(child~ones + parent - 1, data = galton)
lm(child~parent, data =galton)
lm(child~1, data =galton)
head(trees)
fit <- lm(volume~Girth + Height + Constant -1, data =trees)
fit <- lm(Volume~Girth + Height + Constant -1, data =trees)
trees2 <- eliminate("Girth", data = trees)
head(trees2)
fit2 <- lm(Volume~ Height + Constant - 1, data = trees2)
lapply(list(fit, fit2), coef)
x <- c(0.61, 0.93, 0.83, 0.35, 0.54, 0.16, 0.91, 0.62, 0.62)
y <- c(0.67, 0.84, 0.6, 0.18, 0.85, 0.47, 1.1, 0.65, 0.36)
fit <- lm(y~x)
summary(fit)
res <- resid(fit)
sd(res)
data(mtcars)
str(mtcars)
fit2 <- lm(mpg~wt, data = mtcars)
mean(mtcars$wt)
3.217 - (2*0.31)
m <- mean(mtcars$wt)
predict(fit, newdata = data.frame(wt = m), interval = "confidence")
predict(fit, newdata = data.frame(wt = 3.217))
predict(fit2, newdata = data.frame(wt = m), interval = "confidence")
?mtcars
predict(fit2, newdata = data.frame(wt = 3))
predict(fit2, newdata = data.frame(wt = 3), interval = "confidence")
predict(fit2, newdata = data.frame(wt = 3), interval = "prediction")
predict(fit2, newdata = data.frame(wt = 2), interval = "confidence")
fit2 <- lm(mpg~wt, data = mtcars)
summary(fit2)
fit3 <- lm(mpg~1, mtcars)
summary(fit3)
summary(fit)
sd(res)
res <- resid(fit)
sd(res)
predict(fit2, newdata = data.frame(wt = m), interval = "confidence")
predict(fit2, newdata = data.frame(wt = 3), interval = "prediction")
fit4 <- lm(mpg~I(wt/2), data = mtcars)
predict(fit4, newdata = data.frame(wt = 1), interval = "confidence")
fit4 <- lm(mpg~I(wt/2), data = mtcars)
predict(fit4, newdata = data.frame(wt = 1), interval = "confidence")
library(swirl)
swirl()
library(swirl)
swirl()
2
exit()
library(swirl)
swirl()
all <- lm(Fertility~., data =swiss)
summary(all)
lm(Fertility~Agriculture, data = swiss)
summary(lm(Fertility~Agriculture, data = swiss))
corr(Examination,Education)
cor(Examination,Education)
cor(Examination,Education, data =swiss)
cor(Examination,Education)
cor(Examination Education)
cor(Examination,Education)
skip()
cor(swiss$Agriculture, swiss$Education)
makelms()
ec <- sum(swiss$Examination + swiss$Catholic)
ec <- swiss$Examination + swiss$Catholic
efit <- lm(Fertility~. + ec, data = swiss)
coef(all) - coef(efit)
all$coefficients-efit$coefficients
6
dim(InsectSprays)
head(InsectSprays)
head(InsectSprays,15)
skip()
sum(sA[,2])
sum(sA[ ,2])
skip()
sapply(InsectSprays)
skip9)
skip())
skip()
fit <-lm(count~spray, data= InsectSprays)
summary(fit)
summary(fit)$coeff
summary(fit)$coef
skip()
mean(sA)
mean(sB)
nfit <- lm(count~spray -1, data = InsectSprays)
summary(nfit)$coef
spay2 <- relevel(InsectSprays$spray, c)
skip()
fit2 <- lm(count~spray2, data = InsectSprays)
summary(fit2)$coef
mean(sC)
(fit$coef[3]-fit$coef[2])/1.6011
(fit$coef[2]-fit$coef[3])/1.6011
dim(hunger)
948
str(hunger)
names(hunger)
fit <- lm(Numeric~Year, data = hunger)
summary(fit)$coef
skip()
lmM <- lm(hunger$Numeric[hunger$Sex=="Male"] ~ hunger$Year[hunger$Sex=="Male"])
lmBoth <- lm(Numeric~Year + Sex, data =hunger)
summary(lmBoth)$coef
summary(lmBoth)
lmInter <- lm(Numeric~Year + Sex + Sex*Year, data = hunger)
summary(lmInter)
data(mtcars)
str(mtcars)
fit <- lm(mpg~cyl + wt, data = mtcars)
summary(fit)
fit0 <-lm(mpg~cyl, data = mtcars)
summary(fit0)
fit3 <-lm(mpg~cyl + wt + cyl*wt, data = mtcars)
anova(fit3, fit)
lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
f <- lm(y~x)
round(hatvalue(f))
round(hatvalues(f))
dfbeta(f)
hatvalues(f)
dfbeta(f)[, 2]
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
fit6 <- lm(y~x)
dfbetas(fit6)[, 2]
hatvalues(f)
dfbetas(fit6)[, 2]
pairs(mpg ~ ., data = mtcars)
cor(mtcars)
cor(mtcars)
str(mtcars)
summary(stepfit)
pexp(6,1/5,lower.tail = FALSE)
qexp(.25, 1/5)
pexp(11,1/10,lower.tail = FALSE)
1- (0.1*(0.9^3))
library(MASS)
?shuttle
data(shuttle)
str(shuttle)
fit <- glm(use~wind, data = shuttle, family = "binomial")
summry(fit)
summary(fit)
exp(fit$coef)
fit <- glm(use~wind + magn, data = shuttle, family = "binomial")
summary(fit)
exp(fit$coef)
install.packages("caret")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
head(AlzheimerDisease)
data(AlzheimerDisease)
head(predictors)
head(diagnosis)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
head(training)
install.packages("randomForest")
install.packages("rattle")
install.packages("rattle")
require(knitr) # required for knitting from rmd to md
require(markdown) # required for md to html
knit('Assignment.rmd', 'Assigment.md') # creates md file
markdownToHTML('Assignment.md', 'Assignment.html') # creates html file
browseURL(paste('file://', file.path(getwd(),'test.html'), sep=''))
urolith <- read.csv("C:\\Users\\Vachira\Desktop\\Machine1.csv")
urolith <- read.csv("C:/Users/Vachira/Desktop/Machine1.csv")
View(urolith)
View(urolith)
str(urolith)
View(urolith)
View(urolith)
urolith$type
urolith$TYPE
urolith <- read.csv("C:/Users/Vachira/Desktop/Machine1.csv")
str(urolith)
urolith$TYPE
str(urolith)
install.packages("Amelia")
require(Amelia)
missmap(urolith,main = "Missing MAp")
hist(urolith$AGE)
urolith <- read.csv("C:/Users/Vachira/Desktop/Machine1.csv")
str(urolith)
hist(urolith$AGE)
his(urolith$AGE[which(ueolith$STONE == "CaOx")],col = "blue")
hist(urolith$AGE[which(ueolith$STONE == "CaOx")],col = "blue")
hist(urolith$AGE[which(urolith$STONE == "CaOx")],col = "blue")
hist(urolith$AGE[which(urolith$STONE == "MAP")],col = "red")
boxplot(urolith$AGE ~ urolith$STONE)
require(carret)
library(carret)
library(Carret)
install.packages("carret")
urolith <- read.csv("C:/Users/Vachira/Desktop/Machine1.csv")
str(urolith)
install.packages("carret")
install.packages("caret")
library(caret)
require(Amelia)
missmap(urolith,main = "Missing MAp")
inTrain <- createDataPartition(y = urolith$STONE, p = 0.75, list = FALSE)
training <- urolith[inTrain, ]
testing <- urolith[-inTrain, ]
install.packages("party")
require(party)
tree <- ctree(STONE ~ AGE + TYPE + SEX + REPRO, data = training)
tree
plot(tree)
install.packages("C50")
credit <- C5.0(training[-3], training$STONE)
library(C50)
credit <- C5.0(training[-3], training$STONE)
credit
summary(credit)
credit.predict <- predict(credit, testing)
confusionMatrix(credit.predict, testing$STONE)
urolith <- read.csv("C:/Users/Vachira/Desktop/Machine1.csv")
str(urolith)
summary(urolith$AGE)
sd(urolith$AGE)
summary(urolith$TYPE)
summary(urolith$SEX)
summary(urolith$REPRO)
table(urolith$STONE, urolith$type)
table(urolith$STONE, urolith$TYPE)
summary(urolith$SEX)
table(urolith$STONE, urolith$SEX)
table(urolith$STONE, urolith$REPRO)
t.test(urolith$AGE ~ urolith$STONE)
t1 <- table(urolith$STONE, urolith$TYPE)
chisq.test(t1)
t2 <- table(urolith$STONE, urolith$SEX)
chisq.test(t2)
t3 <- table(urolith$STONE, urolith$REPRO)
chisq.test(t3)
library(caret)
inTrain <- createDataPartition(y = urolith$STONE, p = 0.75, list = FALSE)
training <- urolith[inTrain, ]
testing <- urolith[-inTrain, ]
dim(training)
dim(testing)
install.packages("C50")
library(C50)
library(C50)
credit <- C5.0(training[-3], training$STONE)
credit
summary(credit)
credit.predict <- predict(credit, testing)
confusionMatrix(credit.predict, testing$STONE)
credit.predict1 <- predict(credit, training)
confusionMatrix(credit.predict1, training$STONE)
credit.predict2 <- predict(credit, urolith)
confusionMatrix(credit.predict2, urolith$STONE)
setwd("C:\\VACHIRA\\Coursera\\Machinelearning\\Project")
training <- read.csv("train_set.csv", sep = ",", na.strings=c("NA",""))
testing <- read.csv("test_set.csv", sep = ",", na.strings=c("NA",""))
dim(training)
dim(testing)
NAindex <- apply(work.data,2,function(x) {sum(is.na(x))})
work.data <- wor.data[,which(NAindex == 0)]
NAindex <- apply(testing,2,function(x) {sum(is.na(x))})
testing <- testing[,which(NAindex == 0)]
NAindex <- apply(work.data,2,function(x) {sum(is.na(x))})
work.data <- work.data[,which(NAindex == 0)]
NAindex <- apply(testing,2,function(x) {sum(is.na(x))})
testing <- testing[,which(NAindex == 0)]
NAindex <- apply(work.data,2,function(x) {sum(is.na(x))})
NAindex <- apply(training,2,function(x) {sum(is.na(x))})
training <- training[,which(NAindex == 0)]
dim(training)
NAindex <- apply(testing,2,function(x) {sum(is.na(x))})
testing <- testing[,which(NAindex == 0)]
dim(testing)
library(caret)
library(rattle)
library(rpart)
library(randomForest)
str(training)
set.seed(2016)
inTrain = createDataPartition(training$classe, p = 0.75, list = FALSE)
train.set = training[inTrain,]
test.set = training[-inTrain,]
set.seed(2016)
modelFit <- train(train.set$classe ~ . , data = train.set, method = "rpart")
print(modFit)
print(modelFit)
plot(modelFit$finalModel)
text(modelFit$finalModel)
print(modelFit$finalModel)
modelFit <- rpart(train.set$classe ~ . , data = train.set, method = "class")
print(modelFit)
plot(modelFit$finalModel)
fancyRpartPlot(modelFit)
library(C50)
modelFit <- C5.0(train.set[-60],train.set$classe)
print(modelFit)
plot(modelFit$finalModel)
fancyRpartPlot(modelFit)
print(modelFit$finalModel)
print(modelFit)
summary(modelFit)
names(train.set)
train.set <- train.set[-1:2]
train.set <- train.set[,-c(1:2)]
modelFit <- C5.0(train.set[-60],train.set$classe)
summary(modelFit)
print(modelFit)
modelFit <- C5.0(train.set[-58],train.set$classe)
summary(modelFit)
modelFit <- train(train.set$classe~. , data = train.set, method = "rpart")
print(modelFit)
summary(modelFit)
print(modelFit)
library(tree)
modelFit <- tree(classe~. , data = train.set)
fancyRpartPlot(modelFit)
plot(modelFit)
text(modelFit)
modelFit
summary(modelFit)
testing <- read.csv("test_set.csv", sep = ",", na.strings=c("NA",""))
mod_pred <- predict(modelFit, test.set, type = "class")
mean(modelFit != test.set$classe)
mod_pred <- predict(modelFit, test.set, type = "class")
mean(modelFit != test.set$classe)
set.seed(2016)
cv_tree <- cv.tree(model_Fit, FUN = prune.misclass)
set.seed(2016)
cv_tree <- cv.tree(modelFit, FUN = prune.misclass)
plot(cv_tree$size, cv_tree$dev)
plot(cv_tree$size, cv_tree$dev, type = "b")
pruned_model <- prune.misclass(modelFit, best = 18)
plot(pruned_model)
(pruned_model)
text(pruned_model)
summary(pruned_model)
predict.fit <- predict(modelFit, test.set, type = "class")
confusion Matrix(predict.fit, test.set$classe)
confusionMatrix(predict.fit, test.set$classe)
predict.prune <- predict(pruned_model, test.set, type = "class")
confusionMatrix(predict.prune, test.set$classe)
confusionMatrix(predict.fit, test.set$classe)
plot(cv_tree$size, cv_tree$dev, type = "b")
confusionMatrix(predict.prune, test.set$classe)
modRF <- randomForest(classe~ ., data = train.set)
print(modRF)
predict.RF <- predict(modRF, test.set, type = "class")
confusionMatrix(predict.RF,test.set$classe)
predict.US <- predict(modRF, newdata = testing)
testing <- read.csv("test_set.csv", sep = ",", na.strings=c("NA",""))
NAindex <- apply(testing,2,function(x) {sum(is.na(x))})
testing <- testing[,which(NAindex == 0)]
predict.US <- predict(modRF, newdata = testing)
predict.US <- predict(modRF, newdata = testing, tyep = "class")
predict.US <- predict(modRF, testing, tyep = "class")
str(testing)
testing <- read.csv("test_set.csv", sep = ",", na.strings=c("NA",""))
View(testing)
save.image("C:/VACHIRA/Coursera/Machinelearning/Project/new.RData")
predict.US <- predict(modRF, testing, type = "class")
